{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8900,"databundleVersionId":862232,"sourceType":"competition"},{"sourceId":8167622,"sourceType":"datasetVersion","datasetId":4833281}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport math\nimport os\nimport cv2\nimport IPython.display as ipd \nimport librosa \nimport librosa.display\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nimport torchvision\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-19T17:33:35.408263Z","iopub.execute_input":"2024-04-19T17:33:35.409479Z","iopub.status.idle":"2024-04-19T17:33:45.469860Z","shell.execute_reply.started":"2024-04-19T17:33:35.409444Z","shell.execute_reply":"2024-04-19T17:33:45.468916Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:33:57.871708Z","iopub.execute_input":"2024-04-19T17:33:57.873525Z","iopub.status.idle":"2024-04-19T17:33:57.879557Z","shell.execute_reply.started":"2024-04-19T17:33:57.873474Z","shell.execute_reply":"2024-04-19T17:33:57.878216Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"trainPath = '/kaggle/input/freesound-audio-tagging/audio_train/'\ntrainData = pd.read_csv('/kaggle/input/freesound-audio-tagging/train.csv')\ntrainData.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:05.213046Z","iopub.execute_input":"2024-04-19T17:34:05.213623Z","iopub.status.idle":"2024-04-19T17:34:05.254461Z","shell.execute_reply.started":"2024-04-19T17:34:05.213595Z","shell.execute_reply":"2024-04-19T17:34:05.253624Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"          fname         label  manually_verified\n0  00044347.wav        Hi-hat                  0\n1  001ca53d.wav     Saxophone                  1\n2  002d256b.wav       Trumpet                  0\n3  0033e230.wav  Glockenspiel                  1\n4  00353774.wav         Cello                  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>manually_verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00044347.wav</td>\n      <td>Hi-hat</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001ca53d.wav</td>\n      <td>Saxophone</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>002d256b.wav</td>\n      <td>Trumpet</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0033e230.wav</td>\n      <td>Glockenspiel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00353774.wav</td>\n      <td>Cello</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataLabels = np.unique(trainData.label.values)\ndataLabelsEncoder = {dataLabel:i for i, dataLabel in enumerate(dataLabels)}","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:09.855359Z","iopub.execute_input":"2024-04-19T17:34:09.856098Z","iopub.status.idle":"2024-04-19T17:34:09.872718Z","shell.execute_reply.started":"2024-04-19T17:34:09.856062Z","shell.execute_reply":"2024-04-19T17:34:09.871479Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, dataframe, test=False):\n        self.dataframe = dataframe\n        self.test = test\n\n    def __getitem__(self, index):\n        path_to_file = self.get_path_to_file(index)\n        signal = self.preprocess_signal(path_to_file)\n\n        x = np.stack([cv2.resize(signal, (128, 128)) for _ in range(3)])\n\n        if self.test == False:\n            y = dataLabelsEncoder[self.dataframe.label.values[index]]\n            return torch.tensor(x, dtype=torch.float), y\n        else:\n             return torch.tensor(x, dtype=torch.float)\n\n    def get_path_to_file(self, index):\n        if self.test:\n            return '../input/freesound-audio-tagging/audio_test/' + self.dataframe.fname.values[index]\n        else:\n            return '../input/freesound-audio-tagging/audio_train/' + self.dataframe.fname.values[index]\n\n    def preprocess_signal(self, path_to_file):\n        signal, _ = librosa.load(path_to_file)\n        signal = librosa.feature.melspectrogram(y=signal)\n        return librosa.power_to_db(signal, ref=np.max)\n\n    def __len__(self):\n        return self.dataframe.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:12.745050Z","iopub.execute_input":"2024-04-19T17:34:12.745464Z","iopub.status.idle":"2024-04-19T17:34:12.757747Z","shell.execute_reply.started":"2024-04-19T17:34:12.745432Z","shell.execute_reply":"2024-04-19T17:34:12.756621Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\nxTrain, xVal, yTrain, yVal = train_test_split(trainData, trainData, test_size=0.2, shuffle=True, random_state=5)\n\ntrainSet = Dataset(xTrain)\nvalSet = Dataset(xVal)\ntrainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)\nvalLoader = DataLoader(valSet , batch_size=batch_size, shuffle=True)\n\nprint('Training set: {}, Validation set: {}'.format(xTrain.shape[0], xVal.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:15.643257Z","iopub.execute_input":"2024-04-19T17:34:15.643636Z","iopub.status.idle":"2024-04-19T17:34:15.664530Z","shell.execute_reply.started":"2024-04-19T17:34:15.643608Z","shell.execute_reply":"2024-04-19T17:34:15.662939Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Training set: 7578, Validation set: 1895\n","output_type":"stream"}]},{"cell_type":"code","source":"# Путь к локально сохраненным весам модели\nlocal_weights_path = \"/kaggle/input/hahahah/efficientnet_b0_rwightman-7f5810bc.pth\"","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:17.624569Z","iopub.execute_input":"2024-04-19T17:34:17.625782Z","iopub.status.idle":"2024-04-19T17:34:17.630338Z","shell.execute_reply.started":"2024-04-19T17:34:17.625744Z","shell.execute_reply":"2024-04-19T17:34:17.629158Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Загрузка модели без предварительного обучения\nmodel = torchvision.models.efficientnet_b0(pretrained=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:19.139426Z","iopub.execute_input":"2024-04-19T17:34:19.139826Z","iopub.status.idle":"2024-04-19T17:34:19.342494Z","shell.execute_reply.started":"2024-04-19T17:34:19.139795Z","shell.execute_reply":"2024-04-19T17:34:19.341320Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Загрузка локально сохраненных весов\nstate_dict = torch.load(local_weights_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:20.879323Z","iopub.execute_input":"2024-04-19T17:34:20.879705Z","iopub.status.idle":"2024-04-19T17:34:21.107563Z","shell.execute_reply.started":"2024-04-19T17:34:20.879676Z","shell.execute_reply":"2024-04-19T17:34:21.106506Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Загрузка весов в модель\nmodel.load_state_dict(state_dict)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:22.446735Z","iopub.execute_input":"2024-04-19T17:34:22.447155Z","iopub.status.idle":"2024-04-19T17:34:22.476070Z","shell.execute_reply.started":"2024-04-19T17:34:22.447123Z","shell.execute_reply":"2024-04-19T17:34:22.474827Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Изменение последнего слоя модели\nmodel.classifier[1] = torch.nn.Linear(1280, 41)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:34:27.664478Z","iopub.execute_input":"2024-04-19T17:34:27.665597Z","iopub.status.idle":"2024-04-19T17:34:27.672074Z","shell.execute_reply.started":"2024-04-19T17:34:27.665561Z","shell.execute_reply":"2024-04-19T17:34:27.670810Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Перенос модели на устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:37:21.876224Z","iopub.execute_input":"2024-04-19T17:37:21.876655Z","iopub.status.idle":"2024-04-19T17:37:21.899316Z","shell.execute_reply.started":"2024-04-19T17:37:21.876621Z","shell.execute_reply":"2024-04-19T17:37:21.898207Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=True)\n    (1): Linear(in_features=1280, out_features=41, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from time import time \nstart_time = time()\n\nepochs = 1\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncost = torch.nn.CrossEntropyLoss()\ntotal_batches = len(trainLoader)\nfor epoch in range(epochs):\n    train_loss = 0\n    val_loss = 0\n    train_correct = 0\n    val_correct = 0\n    model.train()\n    for batch_idx, (x, y) in enumerate(trainLoader):\n        optimizer.zero_grad()\n        x, y = x.to(device), y.to(device)\n        pred = model(x)\n        loss = cost(pred, y)\n        train_loss += cost(pred, y).item()\n        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n        loss.backward()\n        optimizer.step()\n        # Выводим процент выполнения эпохи\n        percent_complete = ((batch_idx + 1) / total_batches) * 100\n        print(f\"\\rEpoch {epoch + 1}/{epochs} [{int(percent_complete)}%]\", end='')\n\n    model.eval()\n    with torch.no_grad():\n        for x, y in valLoader:\n            x, y = x.to(device), y.to(device)\n            pred = model(x)\n            loss = cost(pred, y)\n            val_loss += cost(pred, y).item()\n            val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    train_loss = train_loss / len(trainLoader)\n    val_loss = val_loss / len(valLoader)\n    train_accuracy = train_correct / len(xTrain)\n    val_accuracy = val_correct / len(xVal)\n    print()\n    print(\"epoch = %d, train_loss = %.5f, val_loss = %.5f, train_accuracy = %.5f, val_accuracy = %.5f\" % (epoch, train_loss, val_loss, train_accuracy, val_accuracy))\n    \nend_time = time()\ntotal_time = end_time - start_time\nprint(f'Total Training Time: {total_time:.2f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T17:37:26.765226Z","iopub.execute_input":"2024-04-19T17:37:26.765622Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/1 [1%]","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n\ntest_dataset = Dataset(test, test=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\npredictions = torch.tensor([])\nmodel.eval()\nfor x in test_loader:\n    x = x.to(device)\n    with torch.no_grad():\n        y_hat = model(x)\n    predictions = torch.cat([predictions, y_hat.cpu()])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = F.softmax(predictions, dim=1).detach().numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_top1 = test.copy()\n\nN = len(test)\nfor i in range(N):\n    p = predictions[i, :]\n    idx = np.argmax(p)\n    submission_top1.label[i] = labels[idx]\n\nsubmission_top1.to_csv('submission_final.csv', index=False, header=True)\n\nsubmission_top1.head()","metadata":{},"execution_count":null,"outputs":[]}]}