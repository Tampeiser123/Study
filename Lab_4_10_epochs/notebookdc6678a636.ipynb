{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8900,"databundleVersionId":862232,"sourceType":"competition"},{"sourceId":8167622,"sourceType":"datasetVersion","datasetId":4833281}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport math\nimport os\nimport cv2\nimport IPython.display as ipd \nimport librosa \nimport librosa.display\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\nimport torchvision\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T14:26:50.254926Z","iopub.execute_input":"2024-04-21T14:26:50.255845Z","iopub.status.idle":"2024-04-21T14:26:50.263464Z","shell.execute_reply.started":"2024-04-21T14:26:50.255809Z","shell.execute_reply":"2024-04-21T14:26:50.262295Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:26:57.167296Z","iopub.execute_input":"2024-04-21T14:26:57.167668Z","iopub.status.idle":"2024-04-21T14:26:57.173493Z","shell.execute_reply.started":"2024-04-21T14:26:57.167632Z","shell.execute_reply":"2024-04-21T14:26:57.172431Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"trainPath = '/kaggle/input/freesound-audio-tagging/audio_train/'\ntrainData = pd.read_csv('/kaggle/input/freesound-audio-tagging/train.csv')\ntrainData.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:27.135482Z","iopub.execute_input":"2024-04-21T14:27:27.135866Z","iopub.status.idle":"2024-04-21T14:27:27.164894Z","shell.execute_reply.started":"2024-04-21T14:27:27.135839Z","shell.execute_reply":"2024-04-21T14:27:27.163819Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"          fname         label  manually_verified\n0  00044347.wav        Hi-hat                  0\n1  001ca53d.wav     Saxophone                  1\n2  002d256b.wav       Trumpet                  0\n3  0033e230.wav  Glockenspiel                  1\n4  00353774.wav         Cello                  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n      <th>manually_verified</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00044347.wav</td>\n      <td>Hi-hat</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001ca53d.wav</td>\n      <td>Saxophone</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>002d256b.wav</td>\n      <td>Trumpet</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0033e230.wav</td>\n      <td>Glockenspiel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00353774.wav</td>\n      <td>Cello</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataLabels = np.unique(trainData.label.values)\ndataLabelsEncoder = {dataLabel:i for i, dataLabel in enumerate(dataLabels)}","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:28.916465Z","iopub.execute_input":"2024-04-21T14:27:28.917430Z","iopub.status.idle":"2024-04-21T14:27:28.928515Z","shell.execute_reply.started":"2024-04-21T14:27:28.917396Z","shell.execute_reply":"2024-04-21T14:27:28.927397Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Dataset(Dataset):\n    def __init__(self, dataframe, test=False):\n        self.dataframe = dataframe\n        self.test = test\n\n    def __getitem__(self, index):\n        path_to_file = self.get_path_to_file(index)\n        signal = self.preprocess_signal(path_to_file)\n\n        x = np.stack([cv2.resize(signal, (128, 128)) for _ in range(3)])\n\n        if self.test == False:\n            y = dataLabelsEncoder[self.dataframe.label.values[index]]\n            return torch.tensor(x, dtype=torch.float), y\n        else:\n             return torch.tensor(x, dtype=torch.float)\n\n    def get_path_to_file(self, index):\n        if self.test:\n            return '../input/freesound-audio-tagging/audio_test/' + self.dataframe.fname.values[index]\n        else:\n            return '../input/freesound-audio-tagging/audio_train/' + self.dataframe.fname.values[index]\n\n    def preprocess_signal(self, path_to_file):\n        signal, _ = librosa.load(path_to_file)\n        signal = librosa.feature.melspectrogram(y=signal)\n        return librosa.power_to_db(signal, ref=np.max)\n\n    def __len__(self):\n        return self.dataframe.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:29.964232Z","iopub.execute_input":"2024-04-21T14:27:29.965057Z","iopub.status.idle":"2024-04-21T14:27:29.975904Z","shell.execute_reply.started":"2024-04-21T14:27:29.964998Z","shell.execute_reply":"2024-04-21T14:27:29.974622Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n\nxTrain, xVal, yTrain, yVal = train_test_split(trainData, trainData, test_size=0.2, shuffle=True, random_state=5)\n\ntrainSet = Dataset(xTrain)\nvalSet = Dataset(xVal)\ntrainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)\nvalLoader = DataLoader(valSet , batch_size=batch_size, shuffle=True)\n\nprint('Training set: {}, Validation set: {}'.format(xTrain.shape[0], xVal.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:37.065833Z","iopub.execute_input":"2024-04-21T14:27:37.066798Z","iopub.status.idle":"2024-04-21T14:27:37.082104Z","shell.execute_reply.started":"2024-04-21T14:27:37.066761Z","shell.execute_reply":"2024-04-21T14:27:37.080864Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Training set: 7578, Validation set: 1895\n","output_type":"stream"}]},{"cell_type":"code","source":"# Путь к локально сохраненным весам модели\nlocal_weights_path = \"/kaggle/input/hahahah/efficientnet_b0_rwightman-7f5810bc.pth\"","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:50.567286Z","iopub.execute_input":"2024-04-21T14:27:50.567695Z","iopub.status.idle":"2024-04-21T14:27:50.572740Z","shell.execute_reply.started":"2024-04-21T14:27:50.567663Z","shell.execute_reply":"2024-04-21T14:27:50.571563Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Загрузка модели без предварительного обучения\nmodel = torchvision.models.efficientnet_b0(pretrained=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:52.456185Z","iopub.execute_input":"2024-04-21T14:27:52.456573Z","iopub.status.idle":"2024-04-21T14:27:52.593308Z","shell.execute_reply.started":"2024-04-21T14:27:52.456545Z","shell.execute_reply":"2024-04-21T14:27:52.592264Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Загрузка локально сохраненных весов\nstate_dict = torch.load(local_weights_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:27:53.596559Z","iopub.execute_input":"2024-04-21T14:27:53.597278Z","iopub.status.idle":"2024-04-21T14:27:53.835069Z","shell.execute_reply.started":"2024-04-21T14:27:53.597226Z","shell.execute_reply":"2024-04-21T14:27:53.833899Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Загрузка весов в модель\nmodel.load_state_dict(state_dict)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:28:12.025401Z","iopub.execute_input":"2024-04-21T14:28:12.026234Z","iopub.status.idle":"2024-04-21T14:28:12.049203Z","shell.execute_reply.started":"2024-04-21T14:28:12.026199Z","shell.execute_reply":"2024-04-21T14:28:12.048134Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"# Изменение последнего слоя модели\nmodel.classifier[1] = torch.nn.Linear(1280, 41)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:28:13.436786Z","iopub.execute_input":"2024-04-21T14:28:13.437216Z","iopub.status.idle":"2024-04-21T14:28:13.443685Z","shell.execute_reply.started":"2024-04-21T14:28:13.437185Z","shell.execute_reply":"2024-04-21T14:28:13.442523Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Перенос модели на устройство\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:28:14.656148Z","iopub.execute_input":"2024-04-21T14:28:14.656524Z","iopub.status.idle":"2024-04-21T14:28:14.675472Z","shell.execute_reply.started":"2024-04-21T14:28:14.656497Z","shell.execute_reply":"2024-04-21T14:28:14.674472Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.2, inplace=True)\n    (1): Linear(in_features=1280, out_features=41, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from time import time \nstart_time = time()\n\nepochs = 10\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncost = torch.nn.CrossEntropyLoss()\ntotal_batches = len(trainLoader)\nfor epoch in range(epochs):\n    train_loss = 0\n    val_loss = 0\n    train_correct = 0\n    val_correct = 0\n    model.train()\n    for batch_idx, (x, y) in enumerate(trainLoader):\n        optimizer.zero_grad()\n        x, y = x.to(device), y.to(device)\n        pred = model(x)\n        loss = cost(pred, y)\n        train_loss += cost(pred, y).item()\n        train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n        loss.backward()\n        optimizer.step()\n        # Выводим процент выполнения эпохи\n        percent_complete = ((batch_idx + 1) / total_batches) * 100\n        print(f\"\\rEpoch {epoch + 1}/{epochs} [{int(percent_complete)}%]\", end='')\n\n    model.eval()\n    with torch.no_grad():\n        for x, y in valLoader:\n            x, y = x.to(device), y.to(device)\n            pred = model(x)\n            loss = cost(pred, y)\n            val_loss += cost(pred, y).item()\n            val_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    train_loss = train_loss / len(trainLoader)\n    val_loss = val_loss / len(valLoader)\n    train_accuracy = train_correct / len(xTrain)\n    val_accuracy = val_correct / len(xVal)\n    print()\n    print(\"epoch = %d, train_loss = %.5f, val_loss = %.5f, train_accuracy = %.5f, val_accuracy = %.5f\" % (epoch, train_loss, val_loss, train_accuracy, val_accuracy))\n    \nend_time = time()\ntotal_time = end_time - start_time\nprint(f'Total Training Time: {total_time:.2f} seconds')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T14:28:25.638241Z","iopub.execute_input":"2024-04-21T14:28:25.639064Z","iopub.status.idle":"2024-04-21T17:10:35.192996Z","shell.execute_reply.started":"2024-04-21T14:28:25.639011Z","shell.execute_reply":"2024-04-21T17:10:35.189251Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/10 [100%]\nepoch = 0, train_loss = 1.76175, val_loss = 1.24012, train_accuracy = 0.51874, val_accuracy = 0.65330\nEpoch 2/10 [100%]\nepoch = 1, train_loss = 0.90961, val_loss = 1.01818, train_accuracy = 0.74083, val_accuracy = 0.72929\nEpoch 3/10 [100%]\nepoch = 2, train_loss = 0.63025, val_loss = 0.97745, train_accuracy = 0.81407, val_accuracy = 0.75303\nEpoch 4/10 [100%]\nepoch = 3, train_loss = 0.46144, val_loss = 0.90171, train_accuracy = 0.86263, val_accuracy = 0.77256\nEpoch 5/10 [100%]\nepoch = 4, train_loss = 0.33400, val_loss = 1.04286, train_accuracy = 0.89338, val_accuracy = 0.75198\nEpoch 6/10 [100%]\nepoch = 5, train_loss = 0.26687, val_loss = 0.93867, train_accuracy = 0.91620, val_accuracy = 0.78734\nEpoch 7/10 [100%]\nepoch = 6, train_loss = 0.20689, val_loss = 1.09658, train_accuracy = 0.93877, val_accuracy = 0.77361\nEpoch 8/10 [100%]\nepoch = 7, train_loss = 0.18990, val_loss = 1.09791, train_accuracy = 0.93983, val_accuracy = 0.77889\nEpoch 9/10 [100%]\nepoch = 8, train_loss = 0.17128, val_loss = 1.20318, train_accuracy = 0.94431, val_accuracy = 0.77573\nEpoch 10/10 [100%]\nepoch = 9, train_loss = 0.14128, val_loss = 1.14801, train_accuracy = 0.95527, val_accuracy = 0.78628\nTotal Training Time: 9729.53 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n\ntest_dataset = Dataset(test, test=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\npredictions = torch.tensor([])\nmodel.eval()\nfor x in test_loader:\n    x = x.to(device)\n    with torch.no_grad():\n        y_hat = model(x)\n    predictions = torch.cat([predictions, y_hat.cpu()])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:11:31.545500Z","iopub.execute_input":"2024-04-21T17:11:31.545951Z","iopub.status.idle":"2024-04-21T17:20:08.776329Z","shell.execute_reply.started":"2024-04-21T17:11:31.545919Z","shell.execute_reply":"2024-04-21T17:20:08.775270Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=0\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = F.softmax(predictions, dim=1).detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:20:32.454012Z","iopub.execute_input":"2024-04-21T17:20:32.454412Z","iopub.status.idle":"2024-04-21T17:20:32.496012Z","shell.execute_reply.started":"2024-04-21T17:20:32.454383Z","shell.execute_reply":"2024-04-21T17:20:32.494602Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m(dim)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'softmax'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'softmax'","output_type":"error"}]},{"cell_type":"code","source":"submission_top1 = test.copy()\n\nN = len(test)\nfor i in range(N):\n    p = predictions[i, :]\n    idx = np.argmax(p)\n    submission_top1.label[i] = dataLabels[idx]\n\nsubmission_top1.to_csv('submission_final.csv', index=False, header=True)\n\nsubmission_top1.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T17:20:36.014756Z","iopub.execute_input":"2024-04-21T17:20:36.015148Z","iopub.status.idle":"2024-04-21T17:20:37.355875Z","shell.execute_reply.started":"2024-04-21T17:20:36.015121Z","shell.execute_reply":"2024-04-21T17:20:37.354907Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/788823920.py:7: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  submission_top1.label[i] = dataLabels[idx]\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"          fname      label\n0  00063640.wav    Shatter\n1  0013a1db.wav      Flute\n2  002bb878.wav  Bass_drum\n3  002d392d.wav  Bass_drum\n4  00326aa9.wav       Oboe","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00063640.wav</td>\n      <td>Shatter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0013a1db.wav</td>\n      <td>Flute</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>002bb878.wav</td>\n      <td>Bass_drum</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>002d392d.wav</td>\n      <td>Bass_drum</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00326aa9.wav</td>\n      <td>Oboe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}